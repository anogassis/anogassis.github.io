---
layout: post
title: AGI Safety Fundamentals - Week 1
date: 2024-02-29
categories: [AGI Safety Fundamentals]
---

# Week 1 Lecture Notes

## Artificial intelligence is transforming our world

### Reasons why it is hard to take the prospect of a world transformed by artificial intelligence seriously

1. In the past, technological advances took place across many generations. Now we have technologies advancing rapidly, and it is common for one to witness multiple technologies becoming common place during his lifetime. Thus, it is "easy to underestimate the speed at which technology can change the world."

2. AGI is something that we first heard in movies. Scenarios that explore what AGI will do to the world need a series of assumptions surrounding it. Thus, it is easy to dismiss these scenarios and consider them "silly".

3. It is difficult to form an idea of a future that is significantly different from ours.

### Developing an idea of what the future might look like

- Human level AI: a system that can perform all actions that humans currently perform.
  - Engineering, research, math, biology, medicine, etc.
  - Pros of concept: Provides a familiar anchor to imagine the capabilities of AGI
  - Cons: Risks obscuring the real differences between Human-GI and AGI
    - Speed of processing information.
    - Large amounts of storage.
    - Speed of domains where AI becomes super human.
    - Failure modes between human intelligence and AGI can be very different.

- Transformative AI: brings a new qualitatively different future to our world.
  - It will be the third transformative event after the agricultural and industrial revolution.

- Risks (too many to list here):
  - Harmful use of AI systems (already happening today).
  - Unaligned AI
    - With human values
    - Goal misgeneralization

- Making sure AI goes well:
  - Funding, engagement, attention

## What risks does AI pose?

### Existing risks

- Harmful malfunction
- Discrimination
- Reducing social connections:
  - Recommender systems can create filter bubbles.
  - Engagement is a poor metric as is can further divide society.
- Invasion of privacy
- Copyright infringement
- Worker exploitation:
  - Human labellers are exposed to harmful content. Mental health risks.

### Anticipated risks

- Bioterrorism:
  - Engineered pandemics.
  - Bioweapons.
  - Discovery of new pathogens.
  - Increased access to technology that can be misused.
- Disinformation:
  - Disinformation campaigns could be cheaper and faster to deploy in large scales.
  - Personalized targeted content may be cheaper to generate.
  - As people start to build relationships with AI friends their data can be exploited.
  - Since only a few actors have the capability of advanced AI currently, they can control the narrative in their favor. Conversely, wide open availability of advanced AI may also pose significant risks too.
- Authoritarianism:
  - Large scale surveillance.
  - Autonomous weapon systems.
  - Population control.
  - Make authoritarian regimes last indefinetely.
- War:
  - Undermine nuclear deterrence.
  - Escalate conflicts inadvertently.
  - Create new incentives for war.

## Readings

- [X] [Artificial intelligence is transforming our world](https://ourworldindata.org/ai-impact)
- [X] [What risks does AI pose?](https://aisafetyfundamentals.com/blog/ai-risks/?_gl=1*1izj8j2*_ga*MTk0NzgwOTgzNC4xNjk2MTg0MDUw*_ga_8W59C8ZY6T*MTcwOTI4OTEyNS4xMy4xLjE3MDkyODkxMjcuMC4wLjA.)